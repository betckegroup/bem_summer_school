
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Low rank compressibility &#8212; BEM Summer School - Lecture Notes</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" href="_static/styles/sphinx-book-theme.css?digest=62ba249389abaaa9ffc34bf36a076bdc1d65ee18" type="text/css" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="_static/design-style.b7bb847fb20b106c3d81b95245e65545.min.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script src="_static/scripts/sphinx-book-theme.js?digest=f31d14ad54b65d19161ba51d4ffff3a77ae00456"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="prev" title="BEM Summer School Lecture Notes" href="intro.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"></div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="_static/logo.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">BEM Summer School - Lecture Notes</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="intro.html">
                    BEM Summer School Lecture Notes
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Fast direct solvers
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   Low rank compressibility
  </a>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
            <div class="navbar_extra_footer">
            Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
            </div>
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<div class="menu-dropdown menu-dropdown-launch-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Launch interactive content">
      <i class="fas fa-rocket"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://mybinder.org/v2/gh/executablebooks/jupyter-book/master?urlpath=tree/low_rank_compression.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Launch on Binder"
>
  

<span class="headerbtn__icon-container">
  
    <img src="_static/images/logo_binder.svg">
  </span>
<span class="headerbtn__text-container">Binder</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>

<div class="menu-dropdown menu-dropdown-download-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Download this page">
      <i class="fas fa-download"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="_sources/low_rank_compression.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Download source file"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="headerbtn__text-container">.ipynb</span>
</a>

      </li>
      
      <li>
        
<button onclick="printPdf(this)"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="left"
title="Print to PDF"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="headerbtn__text-container">.pdf</span>
</button>

      </li>
      
    </ul>
  </div>
</div>
<label for="__page-toc"
  class="headerbtn headerbtn-page-toc"
  
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-list"></i>
  </span>

</label>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
    <div class="tocsection onthispage pt-5 pb-3">
        <i class="fas fa-list"></i> Contents
    </div>
    <nav id="bd-toc-nav" aria-label="Page">
        <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#a-reminder-of-the-singular-value-decomposition">
   A reminder of the Singular Value Decomposition
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#low-rank-approximations">
   Low-rank approximations
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#why-are-low-rank-approximations-useful">
     Why are low-rank approximations useful?
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#the-svd-is-the-best-possible-low-rank-approximation">
   The SVD is the best possible low-rank approximation
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#low-rank-compressibility-of-green-s-functions">
   Low-Rank Compressibility of Green’s functions.
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#separable-expansions">
   Separable expansions
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#taylor-series-are-separable-expansions">
     Taylor series are separable expansions
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#admissibility-conditions">
   Admissibility conditions
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#algebraic-low-rank-approximations">
   Algebraic low-rank approximations
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#pivoted-qr-decomposition">
     Pivoted QR decomposition
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#the-interpolative-decomposition">
     The interpolative decomposition
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#randomized-computation-of-the-qr-decomposition">
     Randomized computation of the QR Decomposition
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#adaptive-cross-approximation-aca">
     Adaptive Cross Approximation (ACA)
    </a>
   </li>
  </ul>
 </li>
</ul>

    </nav>
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Low rank compressibility</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#a-reminder-of-the-singular-value-decomposition">
   A reminder of the Singular Value Decomposition
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#low-rank-approximations">
   Low-rank approximations
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#why-are-low-rank-approximations-useful">
     Why are low-rank approximations useful?
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#the-svd-is-the-best-possible-low-rank-approximation">
   The SVD is the best possible low-rank approximation
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#low-rank-compressibility-of-green-s-functions">
   Low-Rank Compressibility of Green’s functions.
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#separable-expansions">
   Separable expansions
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#taylor-series-are-separable-expansions">
     Taylor series are separable expansions
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#admissibility-conditions">
   Admissibility conditions
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#algebraic-low-rank-approximations">
   Algebraic low-rank approximations
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#pivoted-qr-decomposition">
     Pivoted QR decomposition
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#the-interpolative-decomposition">
     The interpolative decomposition
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#randomized-computation-of-the-qr-decomposition">
     Randomized computation of the QR Decomposition
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#adaptive-cross-approximation-aca">
     Adaptive Cross Approximation (ACA)
    </a>
   </li>
  </ul>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                
  <section class="tex2jax_ignore mathjax_ignore" id="low-rank-compressibility">
<h1>Low rank compressibility<a class="headerlink" href="#low-rank-compressibility" title="Permalink to this headline">#</a></h1>
<section id="a-reminder-of-the-singular-value-decomposition">
<h2>A reminder of the Singular Value Decomposition<a class="headerlink" href="#a-reminder-of-the-singular-value-decomposition" title="Permalink to this headline">#</a></h2>
<p>Let <span class="math notranslate nohighlight">\(A\in\mathbb{C}^{m\times n}\)</span>. Then <span class="math notranslate nohighlight">\(A\)</span> has a singular value decomposition of the form</p>
<div class="math notranslate nohighlight">
\[
A = U\Sigma V^H
\]</div>
<p>with <span class="math notranslate nohighlight">\(U\in\mathbb{C}^{m\times m}\)</span>, <span class="math notranslate nohighlight">\(V\in\mathbb{n\times n}\)</span> unitary, that is <span class="math notranslate nohighlight">\(U^HU=I\)</span> and <span class="math notranslate nohighlight">\(V^HV=I\)</span>.</p>
<p>The matrix <span class="math notranslate nohighlight">\(\Sigma\in\mathbb{R}^{m\times n}\)</span> is a diagonal matrix with diagonal elements</p>
<p><span class="math notranslate nohighlight">\(\sigma_1\geq \sigma_2\dots \geq \sigma_r &gt; 0\)</span>. Here <span class="math notranslate nohighlight">\(r\)</span> is the rank of the matrix. From now on we assume
that <span class="math notranslate nohighlight">\(r = \min\{m, n\}\)</span>.</p>
</section>
<section id="low-rank-approximations">
<h2>Low-rank approximations<a class="headerlink" href="#low-rank-approximations" title="Permalink to this headline">#</a></h2>
<p>Let <span class="math notranslate nohighlight">\(A\in\mathbb{C}^{m\times n}\)</span>. If</p>
<div class="math notranslate nohighlight">
\[
M\approx CZ^H 
\]</div>
<p>for <span class="math notranslate nohighlight">\(C, Z\in\mathbb{C}^{m\times k}\)</span> with <span class="math notranslate nohighlight">\(k\ll \min\{m, n\}\)</span></p>
<p>we say that <span class="math notranslate nohighlight">\(A\)</span> has a low-rank approximation of rank <span class="math notranslate nohighlight">\(k\)</span>.</p>
<section id="why-are-low-rank-approximations-useful">
<h3>Why are low-rank approximations useful?<a class="headerlink" href="#why-are-low-rank-approximations-useful" title="Permalink to this headline">#</a></h3>
<p>Let <span class="math notranslate nohighlight">\(A\in\mathbb{C}^{n\times n}\)</span> and assume <span class="math notranslate nohighlight">\(A\)</span> has a
low-rank approximation <span class="math notranslate nohighlight">\(A=CZ^H\)</span> of rank <span class="math notranslate nohighlight">\(k\)</span>.</p>
<p><span class="math notranslate nohighlight">\(A\)</span> has <span class="math notranslate nohighlight">\(\mathcal{O}(n^2)\)</span> storage cost and also <span class="math notranslate nohighlight">\(\mathcal{O}(n^2)\)</span>
for a matvec (matrix-vector product).</p>
<p><span class="math notranslate nohighlight">\(CZ^H\)</span> has <span class="math notranslate nohighlight">\(\mathcal{O}(nk)\)</span> storage cost and also <span class="math notranslate nohighlight">\(\mathcal{O}(nk)\)</span>
cost for a matvec.</p>
<p><em>If k is independent of <span class="math notranslate nohighlight">\(n\)</span> then the cost of the low-rank expansion
scales linearly in <span class="math notranslate nohighlight">\(n\)</span></em>.</p>
</section>
</section>
<section id="the-svd-is-the-best-possible-low-rank-approximation">
<h2>The SVD is the best possible low-rank approximation<a class="headerlink" href="#the-svd-is-the-best-possible-low-rank-approximation" title="Permalink to this headline">#</a></h2>
<p>Let <span class="math notranslate nohighlight">\(A \in \mathbb{C}^{m\times n}\)</span> with SVD <span class="math notranslate nohighlight">\(A=U\Sigma V^H\)</span>.</p>
<p>Then <span class="math notranslate nohighlight">\(A_k = \sum_{j=1}^k \sigma_j u_jv_j^H\)</span> is the best possible
approximation to <span class="math notranslate nohighlight">\(A\)</span> in the sense that</p>
<div class="math notranslate nohighlight">
\[
\sigma_{k+1} = \|A - A_k\|_2 \leq \|A-F\|_2
\]</div>
<p>for every matrix <span class="math notranslate nohighlight">\(F\in\mathbb{C}^{m\times n}\)</span> of rank at most <span class="math notranslate nohighlight">\(k\)</span>.</p>
<p>We will later learn about heuristic techniques to efficiently compute low-rank approximations
without relying on the expensive SVD.</p>
</section>
<section id="low-rank-compressibility-of-green-s-functions">
<h2>Low-Rank Compressibility of Green’s functions.<a class="headerlink" href="#low-rank-compressibility-of-green-s-functions" title="Permalink to this headline">#</a></h2>
<p>Let <span class="math notranslate nohighlight">\(g(x, y) = \frac{1}{4\pi|x -y|}\)</span> be the usual Laplace Green’s function in three dimensions.</p>
<p>Let <span class="math notranslate nohighlight">\(Y\subset \mathbb{R}^3\)</span> be a set of sources and <span class="math notranslate nohighlight">\(X\in\mathbb{R}^3\)</span> be a set of targets. We assume that <span class="math notranslate nohighlight">\(X\)</span> and <span class="math notranslate nohighlight">\(Y\)</span> are well separated (we will make this more precise later).</p>
<p>Let <span class="math notranslate nohighlight">\(x_i\in X\)</span> and <span class="math notranslate nohighlight">\(y_j\in Y\)</span> with <span class="math notranslate nohighlight">\(i, j=1,\dots, N\)</span>. Denote by <span class="math notranslate nohighlight">\(G\)</span> the matrix of interactions defined by</p>
<div class="math notranslate nohighlight">
\[
g_{ij} = g(x_i, y_j).
\]</div>
<p>As long as <span class="math notranslate nohighlight">\(X\)</span> and <span class="math notranslate nohighlight">\(Y\)</span> are well separated <span class="math notranslate nohighlight">\(G\)</span> can be well approximated by a low-rank matrix.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">scipy.linalg</span> <span class="kn">import</span> <span class="n">svdvals</span>
<span class="kn">from</span> <span class="nn">matplotlib</span> <span class="kn">import</span> <span class="n">pyplot</span> <span class="k">as</span> <span class="n">plt</span>

<span class="o">%</span><span class="k">matplotlib</span> inline

<span class="n">plt</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">&#39;figure.figsize&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="mi">10</span><span class="p">,</span> <span class="mi">8</span><span class="p">]</span>

<span class="n">dist</span> <span class="o">=</span> <span class="mf">2.0</span>
<span class="n">N</span> <span class="o">=</span> <span class="mi">100</span>

<span class="n">targets</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="n">N</span><span class="p">)</span>
<span class="n">sources</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="n">N</span><span class="p">)</span> <span class="o">+</span> <span class="n">dist</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

<span class="n">G</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">N</span><span class="p">,</span> <span class="n">N</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">N</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">N</span><span class="p">):</span>
        <span class="n">G</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">/</span> <span class="p">(</span><span class="mi">4</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">pi</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">targets</span><span class="p">[:,</span> <span class="n">i</span><span class="p">]</span> <span class="o">-</span> <span class="n">sources</span><span class="p">[:,</span> <span class="n">j</span><span class="p">]))</span>

<span class="n">s</span> <span class="o">=</span> <span class="n">svdvals</span><span class="p">(</span><span class="n">G</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">semilogy</span><span class="p">(</span><span class="n">s</span> <span class="o">/</span> <span class="n">s</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;rank k&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">18</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;$\sigma_k$&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">18</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Text(0, 0.5, &#39;$\\sigma_k$&#39;)
</pre></div>
</div>
<img alt="_images/low_rank_compression_6_1.png" src="_images/low_rank_compression_6_1.png" />
</div>
</div>
<p>We see that a rank of around <span class="math notranslate nohighlight">\(10\)</span> is enough to approximate the original matrix <span class="math notranslate nohighlight">\(M\)</span> with an accuracy of <span class="math notranslate nohighlight">\(10^{-5}\)</span>.</p>
</section>
<section id="separable-expansions">
<h2>Separable expansions<a class="headerlink" href="#separable-expansions" title="Permalink to this headline">#</a></h2>
<p>A separable expansion is an expression of the form</p>
<div class="math notranslate nohighlight">
\[
g(x, y) = \sum_{j=1}^k\phi_j(x)\psi_j(y) + R_k(x, y)
\]</div>
<p>for <span class="math notranslate nohighlight">\(x\in X\)</span> and <span class="math notranslate nohighlight">\(y\in Y\)</span>.</p>
<p>Here, the <span class="math notranslate nohighlight">\(\phi_j\)</span> and <span class="math notranslate nohighlight">\(\psi_j\)</span> are suitable chosen functions and <span class="math notranslate nohighlight">\(R_k\)</span> is a remainder term.</p>
<p>A separable expansion is the continuous equivalent to a low-rank approximation. Let <span class="math notranslate nohighlight">\(G\)</span> be the matrix of Green’s function interactions.
Define</p>
<div class="math notranslate nohighlight">
\[
C_{ij} = \phi_j(x_i),\quad Z_{ij} = \overline{\psi_j(y_i)}.
\]</div>
<p>Then</p>
<div class="math notranslate nohighlight">
\[
G = CZ^H + R_k(x_i, y_j).
\]</div>
<section id="taylor-series-are-separable-expansions">
<h3>Taylor series are separable expansions<a class="headerlink" href="#taylor-series-are-separable-expansions" title="Permalink to this headline">#</a></h3>
<p>Fix <span class="math notranslate nohighlight">\(x_0\in X\)</span>. Then the degree <span class="math notranslate nohighlight">\(m\)</span> Taylor expansion is given as</p>
<div class="math notranslate nohighlight">
\[
g(x, y) = \sum_{\alpha \in N^d, |\alpha|\leq m} (x- x_0)^{\alpha}\frac{1}{\alpha !}\partial_x^{\alpha}g(x_0, y) + R_k(x, y).
\]</div>
<p>The index <span class="math notranslate nohighlight">\(k\)</span> is the number of terms in the Taylor expansion and given as <span class="math notranslate nohighlight">\(k=\left(\begin{array}{c}m+d\\ d\end{array}\right)\)</span>.</p>
<p>The parameter <span class="math notranslate nohighlight">\(k\)</span> is the space dimension. In our case <span class="math notranslate nohighlight">\(d=3\)</span>.</p>
<p>An alternative to Taylor series is separable expansion by interpolation, or in the case of Laplace/Helmholtz type kernels spherical harmonics
type expansions.</p>
<p>No matter what type of expansion we choose, we need to ensure that the remainder term <span class="math notranslate nohighlight">\(R_k\)</span> decays for increasing <span class="math notranslate nohighlight">\(k\)</span>.</p>
</section>
</section>
<section id="admissibility-conditions">
<h2>Admissibility conditions<a class="headerlink" href="#admissibility-conditions" title="Permalink to this headline">#</a></h2>
<p>To ensure rapid decay of the error term the sets <span class="math notranslate nohighlight">\(X\)</span> and <span class="math notranslate nohighlight">\(Y\)</span> need to be sufficiently far apart from each other.</p>
<p>If we can expand in <span class="math notranslate nohighlight">\(x\)</span> or <span class="math notranslate nohighlight">\(y\)</span> then the admissibility condition is that</p>
<div class="math notranslate nohighlight">
\[
\min \{\text{diam}(X), \text{diam}(Y)\} \leq \eta\, \text{dist}(X, Y)
\]</div>
<p>for some sufficiently small <span class="math notranslate nohighlight">\(\eta&gt; 0\)</span>.</p>
<p>This leads to an exponential error bound for the remainder term <span class="math notranslate nohighlight">\(R_k\)</span> in the Taylor expansion of the form</p>
<div class="math notranslate nohighlight">
\[
\| R_k\|_{\infty, X\times Y} = c_1(c_2\eta)^{m}
\]</div>
<p>for constants <span class="math notranslate nohighlight">\(c_1\)</span> and <span class="math notranslate nohighlight">\(c_2\)</span>. Hence, for <span class="math notranslate nohighlight">\(\eta &lt; c_2^{-1}\)</span> the error will decay rapidly.</p>
<p>In practice, the choice of <span class="math notranslate nohighlight">\(\eta\)</span> is usually less crucial if we choose algebraic low-rank approximations and not
analytic series expansions.</p>
</section>
<section id="algebraic-low-rank-approximations">
<h2>Algebraic low-rank approximations<a class="headerlink" href="#algebraic-low-rank-approximations" title="Permalink to this headline">#</a></h2>
<p>We have already seen that the SVD provides a low-rank approximation. However, while optimal the SVD is expensive to compute. In the following we discuss
a number of other low-rank approximation techniques that in practice provide nearly optimal results and are cheaper than the SVD.</p>
<section id="pivoted-qr-decomposition">
<h3>Pivoted QR decomposition<a class="headerlink" href="#pivoted-qr-decomposition" title="Permalink to this headline">#</a></h3>
<p>Let <span class="math notranslate nohighlight">\(A\in\mathbb{C}^{m\times n}\)</span> and <span class="math notranslate nohighlight">\(r=\min\{m, n\}\)</span>. Then the pivoted QR decomposition of <span class="math notranslate nohighlight">\(A\)</span> has the form</p>
<div class="math notranslate nohighlight">
\[
AP = QR
\]</div>
<p><span class="math notranslate nohighlight">\(P\)</span> is a permutation matrix (exactly one element in each row/column is <span class="math notranslate nohighlight">\(1\)</span>, all others are zero.). <span class="math notranslate nohighlight">\(Q\in\mathbb{C}^{m\times r}\)</span> has orthogonal columns, and <span class="math notranslate nohighlight">\(R\in\mathbb{C}^{r\times n}\)</span> is upper triangular
with diagonal elements <span class="math notranslate nohighlight">\(r_ii\)</span> sorted in decreasing order, that is <span class="math notranslate nohighlight">\(|r_{ii}|\geq |r_{i+1, i+1}|\)</span>.</p>
<p>The pivoted QR decomposition naturally gives rise to a low rank approximation. Choose <span class="math notranslate nohighlight">\(k&lt;r\)</span>. Let <span class="math notranslate nohighlight">\(Q_k = Q[:, 1\dots k]\)</span> and <span class="math notranslate nohighlight">\(R_k = R[1\dots k, :]\)</span>. We then have</p>
<div class="math notranslate nohighlight">
\[
A\approx CZ^H
\]</div>
<p>with <span class="math notranslate nohighlight">\(C = Q_k\)</span> and <span class="math notranslate nohighlight">\(Z = R_k^HP^H\)</span>.</p>
</section>
<section id="the-interpolative-decomposition">
<h3>The interpolative decomposition<a class="headerlink" href="#the-interpolative-decomposition" title="Permalink to this headline">#</a></h3>
<p>The original matrix <span class="math notranslate nohighlight">\(G\)</span> encodes physical information, e.g. the Green’s function interactions between source and target points. With the previous low-rank representations the matrices <span class="math notranslate nohighlight">\(C\)</span> and <span class="math notranslate nohighlight">\(Z\)</span> have no direct physical meaning. A solution is the interpolative decomposition. We partition the pivoted QR decomposition
as follows.</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
AP &amp;= \begin{bmatrix}Q_k &amp; \tilde{Q}\end{bmatrix}\begin{bmatrix}R_k[:, 1\dots k] &amp; \tilde{R}\\ 0 &amp; \hat{R}\end{bmatrix}\\
  &amp;= Q_kR_k[:, 1\dots k]\begin{bmatrix}I &amp; R_k[:, 1\dots k]^{-1}\tilde{R}\end{bmatrix} + \tilde{Q}\begin{bmatrix}0 &amp; \hat{R}\end{bmatrix}
\end{aligned}
\end{split}\]</div>
<p>The second term is discarded in the low-rank approximation. Also note that the product <span class="math notranslate nohighlight">\(Q_kR_k[:, 1\dots k]\)</span> is identical to the first <span class="math notranslate nohighlight">\(k\)</span> columns of <span class="math notranslate nohighlight">\(AP\)</span>. We hence obtain</p>
<div class="math notranslate nohighlight">
\[
A = CZ^H
\]</div>
<p>with <span class="math notranslate nohighlight">\(C\)</span> consisting of the first <span class="math notranslate nohighlight">\(k\)</span> columns of <span class="math notranslate nohighlight">\(AP\)</span> and <span class="math notranslate nohighlight">\(Z^H = \begin{bmatrix}I &amp; R_k[:, 1\dots k]^{-1}\tilde{R}\end{bmatrix}P^H\)</span>.</p>
<p>The advantage of this decomposition is that the matrix <span class="math notranslate nohighlight">\(C\)</span> now has physical meaning. With a little bit more linear algebra work we can derive a both sided interpolative decomposition of the form</p>
<div class="math notranslate nohighlight">
\[
A = CA[J, J]Z^H,
\]</div>
<p>where <span class="math notranslate nohighlight">\(C\in\mathbb{C}^{m\times k}\)</span>, <span class="math notranslate nohighlight">\(Z\in\mathbb{C}^{n\times k}\)</span> and <span class="math notranslate nohighlight">\(A[J, j]\)</span> is a <span class="math notranslate nohighlight">\(k\times k\)</span> submatrix of
<span class="math notranslate nohighlight">\(A\)</span> obtained from an index set <span class="math notranslate nohighlight">\(J\)</span>.</p>
</section>
<section id="randomized-computation-of-the-qr-decomposition">
<h3>Randomized computation of the QR Decomposition<a class="headerlink" href="#randomized-computation-of-the-qr-decomposition" title="Permalink to this headline">#</a></h3>
<p>Computing an exact QR decomposition can be expensive for larger matrices. Randomized methods often give excellent approximations with a fraction of the cost of an exact QR decomposition.</p>
<p>The core of the idea is based on randomized range detection. Let <span class="math notranslate nohighlight">\(\Omega\subset\mathbb{C}^{n\times k'}\)</span> whose entries are independently distributed Gaussian random numbers. Furthermore, <span class="math notranslate nohighlight">\(k' = k +p\)</span>, where <span class="math notranslate nohighlight">\(k\)</span> is the desired rank and <span class="math notranslate nohighlight">\(p\)</span> a small oversampling parameter.</p>
<p>We first compute <span class="math notranslate nohighlight">\(Y = A\Omega\)</span> and then the QR decomposition <span class="math notranslate nohighlight">\(Y = QR\)</span>. This is cheap with a cost of <span class="math notranslate nohighlight">\(\mathcal{O}(m\times k')\)</span>.</p>
<p>An approximation to <span class="math notranslate nohighlight">\(A\)</span> is now obtained by <span class="math notranslate nohighlight">\(A\approx QQ^HA\)</span>. To compute a pivoted QR decomposition of <span class="math notranslate nohighlight">\(A\)</span> we compute the pivoted QR decomposition <span class="math notranslate nohighlight">\(Q^HAP = \hat{Q}R\)</span> of <span class="math notranslate nohighlight">\(Q^HA\)</span>. Again, this is a cheap operation. The approximate pivoted QR decomposition of the original matrix <span class="math notranslate nohighlight">\(A\)</span> is now obtained as</p>
<div class="math notranslate nohighlight">
\[
AP \approx Q\hat{Q}R
\]</div>
<p>By discarding the <span class="math notranslate nohighlight">\(p\)</span> last columns of <span class="math notranslate nohighlight">\(\hat{Q}\)</span> and the corresponding <span class="math notranslate nohighlight">\(p\)</span> last rows of <span class="math notranslate nohighlight">\(R\)</span> this reduces to an approximate QR decomposition of rank <span class="math notranslate nohighlight">\(k\)</span>.</p>
<p>If the singular values of the matrix <span class="math notranslate nohighlight">\(A\)</span> are rapidly decaying this is an excellent method to compute an approximate low-rank decomposition with very low computational cost.</p>
</section>
<section id="adaptive-cross-approximation-aca">
<h3>Adaptive Cross Approximation (ACA)<a class="headerlink" href="#adaptive-cross-approximation-aca" title="Permalink to this headline">#</a></h3>
<p>To compute a low-rank approximation with the previously discussed methods we need to at least be able to compute an approximate range of <span class="math notranslate nohighlight">\(A\)</span> by multiplication with a random matrix <span class="math notranslate nohighlight">\(\Omega\)</span>. If <span class="math notranslate nohighlight">\(A\)</span> represents Green’s function interactions we can compute the matrix entries on the fly as we pass through the product. This reduces the memory cost. But we still have computational cost of <span class="math notranslate nohighlight">\(\mathcal{O}(m\times n)\)</span>.</p>
<p>Adaptive cross approximation is an algorithm that only needs to touch a subset of the rows and columns of <span class="math notranslate nohighlight">\(A\)</span> and hence can give a low-rank approximation with much lower computational cost.</p>
<p>The idea is straight forward. Given the matrix <span class="math notranslate nohighlight">\(A\in\mathbb{C}^{\times n}\)</span>. Define <span class="math notranslate nohighlight">\(R_0:=A\)</span>. Choose a row <span class="math notranslate nohighlight">\(i_1\)</span> and select <span class="math notranslate nohighlight">\(j_1\)</span> such that <span class="math notranslate nohighlight">\(R_0[i_1, j_1]\)</span> is the by magnitude largest element in row <span class="math notranslate nohighlight">\(i_1\)</span>.</p>
<p>We now compute</p>
<div class="math notranslate nohighlight">
\[
R_1 := R_0 - \frac{1}{R_0[i_1, j_1]}R_0[:, j_1]R_0[i_1, :].
\]</div>
<p>By repeating this procedure with <span class="math notranslate nohighlight">\(R_1\)</span> instead of <span class="math notranslate nohighlight">\(R_0\)</span>, and so on, we build up a low rank approximation</p>
<div class="math notranslate nohighlight">
\[
S_k = \sum_{\ell=1}^k \frac{1}{R_{\ell-1}[i_\ell, j_\ell]}R_{\ell-1}[:, j_\ell]R_{\ell-1}[i_\ell, :]
\]</div>
<p>such that <span class="math notranslate nohighlight">\(A = S_k + R_k\)</span>.</p>
<p>We are not discussing adaptive stopping criteria and the right choice of the row indices <span class="math notranslate nohighlight">\(i_k\)</span> here. ACA is highly effective for kernel matrices arising from smooth kernels. However, it can fail if the underlying kernel function is not smooth (e.g. a double-layer kernel on over the boundary of a cube).</p>
</section>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
    <a class='left-prev' id="prev-link" href="intro.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">BEM Summer School Lecture Notes</p>
        </div>
    </a>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><p>
  
    By Timo Betcke<br/>
  
      &copy; Copyright 2022.<br/>
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>


  </body>
</html>